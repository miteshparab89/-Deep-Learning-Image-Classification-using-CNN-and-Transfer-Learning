{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66a48c-128a-4d1a-8bd3-09c1873e1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import catppuccin\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Rescaling\n",
    "\n",
    "mpl.style.use(catppuccin.PALETTE.mocha.identifier)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train_grayscaled = np.dot(X_train[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "X_test_grayscaled = np.dot(X_test[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "normalization_layer = Rescaling(1./255)\n",
    "X_train_grayscaled = normalization_layer(X_train_grayscaled)\n",
    "X_test_grayscaled = normalization_layer(X_test_grayscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e065ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling\n",
    "\n",
    "model = Sequential([\n",
    "    Rescaling(1./255),\n",
    "    # First convolutional layer with 32 filters, 3x3 kernel, ReLU activation\n",
    "    # Input shape is 32x32 pixels with 3 color channel (grayscale)\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    # Max pooling layer to reduce spatial dimensions by a factor of 2\n",
    "    MaxPooling2D(2,2),\n",
    "    # Second convolutional layer with 64 filters, 3x3 kernel, ReLU activation\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    # Another max pooling layer to reduce size further\n",
    "    MaxPooling2D(2,2),\n",
    "    # Flatten the 2D feature maps into a 1D vector for dense layers\n",
    "    Flatten(),\n",
    "    # Fully connected (dense) layer with 128 neurons and ReLU activation\n",
    "    #Learns intermediate features from the previous layers\n",
    "    Dense(128, activation='relu'),\n",
    "    # Output layer with 10 neurons (for 10 classes) and softmax activation\n",
    "    #Produces the final probabilities for each class.\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_test, y_test),\n",
    ")\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy of baseline model: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6966d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"initial_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9996ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the other (more complex) model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, Nadam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_more_layers = Sequential([\n",
    "    Rescaling(1./255),\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.4),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Flatten(),\n",
    "    #Produces the final probabilities for each class.\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model_more_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 1e-2\n",
    "epochs = 300\n",
    "\n",
    "adam = Adam(\n",
    "    learning_rate=learning_rate,\n",
    ")\n",
    "nadam = Nadam(\n",
    "    learning_rate=learning_rate,\n",
    ")\n",
    "sgd = SGD(\n",
    "    learning_rate=learning_rate,\n",
    "    nesterov=True,\n",
    ")\n",
    "\n",
    "model_more_layers.compile(\n",
    "    optimizer=sgd,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=6,\n",
    "    min_lr=1e-4,\n",
    ")\n",
    "\n",
    "# Train on original data\n",
    "history_more_layers = model_more_layers.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model_more_layers.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy with more layers: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_more_layers.save(\"model_with_more_layers.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ab393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning model 1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, InputLayer, Resizing\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, Nadam, SGD, Adadelta\n",
    "from keras.applications import EfficientNetB0, EfficientNetV2S, EfficientNetV2B0, MobileNetV3Large, MobileNetV2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd15ac",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "base_model = MobileNetV3Large(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    ")\n",
    "base_model.trainable=False\n",
    "\n",
    "model = Sequential([\n",
    "    Resizing(32*5, 32*5),\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "adadelta = Adadelta(learning_rate=0.1)\n",
    "model.compile(\n",
    "    optimizer=adadelta,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=6,\n",
    "    min_lr=1e-4,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    validation_data=[X_test, y_test]\n",
    ")\n",
    "\n",
    "est_loss, test_acc = model.evaluate(tf.image.resize(X_test, (32*5, 32*5)), y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b632eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"transfer-learning1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7558c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning model 2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, InputLayer\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, Nadam, SGD, Adadelta\n",
    "from keras.applications import EfficientNetB0, EfficientNetV2S, EfficientNetV2B0, MobileNetV3Large, MobileNetV2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefcd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV3Large(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    ")\n",
    "\n",
    "image_resize_factor = 5\n",
    "base_model.trainable=False\n",
    "fraction_retrained_layers = .3\n",
    "layer_count = len(base_model.layers)\n",
    "layers_to_retrain = round(layer_count * fraction_retrained_layers)\n",
    "for layer in base_model.layers[-layers_to_retrain:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model = Sequential([\n",
    "    Resizing(32*image_resize_factor, 32*image_resize_factor),\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "adadelta = Adadelta(learning_rate=0.1)\n",
    "model.compile(\n",
    "    optimizer=adadelta,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=6,\n",
    "    min_lr=1e-4,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    validation_data=[tf.image.resize(X_test, (32*image_resize_factor, 32*image_resize_factor)), y_test]\n",
    ")\n",
    "\n",
    "est_loss, test_acc = model.evaluate(tf.image.resize(X_test, (32*image_resize_factor, 32*image_resize_factor)), y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eda5c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./transfer-learning2-with-partial-retrain-of-base-model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
